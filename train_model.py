import pandas as pd
import pickle
import argparse
import os
 from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

def train_email_classifier(data_file='emails.csv'):
    """
    Train an email classification model using TfidfVectorizer and LogisticRegression
    
    Args:
        data_file: Path to the CSV file containing training data
    """
    print(f"Loading data from {data_file}...")
    
    # Check if file exists
    if not os.path.exists(data_file):
        print(f"âŒ Error: File '{data_file}' not found!")
        print("\nğŸ’¡ æç¤º:")
        if data_file == 'emails_real.csv':
            print("   è¯·å…ˆè¿è¡Œ: python prepare_training_data.py")
            print("   æ¥å‡†å¤‡çœŸå®çš„Gmailè®­ç»ƒæ•°æ®")
        return False
    
    # Load the dataset
    df = pd.read_csv(data_file)
    
    print(f"Loaded {len(df)} emails")
    print(f"Label distribution:\n{df['label'].value_counts()}\n")
    
    # Combine subject and body into a single text field
    df['text'] = df['subject'].fillna('') + ' ' + df['body'].fillna('')
    
    # Prepare features and labels
    X = df['text']
    y = df['label']
    
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print("Vectorizing text with TfidfVectorizer (max 1000 features)...")
    # Create TfidfVectorizer with max 1000 features
    vectorizer = TfidfVectorizer(
        max_features=1000,
        stop_words='english',
        ngram_range=(1, 2),  # Use unigrams and bigrams
        min_df=2  # Ignore terms that appear in less than 2 documents
    )
    
    # Fit and transform training data
    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)
    
    print("Training LogisticRegression model...")
    # Train Logistic Regression model
    model = LogisticRegression(
        max_iter=1000,
        random_state=42,
        class_weight='balanced'  # Handle imbalanced classes
    )
    model.fit(X_train_vec, y_train)
    
    # Evaluate the model
    y_pred = model.predict(X_test_vec)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nModel Accuracy: {accuracy:.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    
    # Save the model and vectorizer
    print("\nSaving model to model.pkl...")
    with open('model.pkl', 'wb') as f:
        pickle.dump(model, f)
    
    print("Saving vectorizer to vectorizer.pkl...")
    with open('vectorizer.pkl', 'wb') as f:
        pickle.dump(vectorizer, f)
    
    print("\nâœ“ Training complete! Model and vectorizer saved successfully.")
    print(f"âœ“ Model can predict {len(model.classes_)} classes: {list(model.classes_)}")
    
    return True

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='è®­ç»ƒé‚®ä»¶åˆ†ç±»æ¨¡å‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨mockæ•°æ®è®­ç»ƒï¼ˆé»˜è®¤ï¼‰
  python train_model.py
  
  # ä½¿ç”¨çœŸå®Gmailæ•°æ®è®­ç»ƒ
  python train_model.py --data emails_real.csv
  
  # ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®æ–‡ä»¶
  python train_model.py --data path/to/your/data.csv

æ³¨æ„: 
  - æ•°æ®æ–‡ä»¶å¿…é¡»åŒ…å« 'subject', 'body', 'label' ä¸‰åˆ—
  - ä½¿ç”¨çœŸå®æ•°æ®å‰ï¼Œè¯·å…ˆè¿è¡Œ: python prepare_training_data.py
        """
    )
    
    parser.add_argument(
        '--data',
        type=str,
        default='emails.csv',
        help='è®­ç»ƒæ•°æ®CSVæ–‡ä»¶è·¯å¾„ (é»˜è®¤: emails.csv)'
    )
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒé‚®ä»¶åˆ†ç±»æ¨¡å‹")
    print("="*60)
    print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {args.data}")
    print()
    
    success = train_email_classifier(args.data)
    
    if success:
        print("\n" + "="*60)
        print("âœ… è®­ç»ƒæˆåŠŸï¼")
        print("="*60)
        print("\næ¨¡å‹æ–‡ä»¶:")
        print(f"  - model.pkl (åˆ†ç±»æ¨¡å‹)")
        print(f"  - vectorizer.pkl (æ–‡æœ¬å‘é‡åŒ–å™¨)")
        print("\nä½ ç°åœ¨å¯ä»¥:")
        print("  1. å¯åŠ¨æœåŠ¡æµ‹è¯•æ¨¡å‹: npm run dev")
        print("  2. ä½¿ç”¨Chromeæ‰©å±•è‡ªåŠ¨åˆ†ç±»é‚®ä»¶")
        print("  3. åœ¨åç«¯APIä¸­ä½¿ç”¨åˆ†ç±»åŠŸèƒ½")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥ï¼è¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯ã€‚")
