version: '3.8'

services:
  # Backend Node.js API
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: jobtrack-backend
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - FRONTEND_URL=http://localhost
    volumes:
      - ./backend/data:/app/data
      - ./backend/export:/app/export
    networks:
      - jobtrack-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Python ML Service
  python-api:
    build:
      context: .
      dockerfile: Dockerfile.python
    container_name: jobtrack-python
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - MODEL_PATH=/app/model.pkl
      - VECTORIZER_PATH=/app/vectorizer.pkl
    volumes:
      - ./model.pkl:/app/model.pkl:ro
      - ./vectorizer.pkl:/app/vectorizer.pkl:ro
      - ./backend/export:/app/backend/export:ro
      - ./model_backups:/app/model_backups
    networks:
      - jobtrack-network
    restart: unless-stopped
    depends_on:
      - backend

  # Frontend React App with Nginx
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: jobtrack-frontend
    ports:
      - "80:80"
    environment:
      - VITE_API_URL=http://localhost:3000
      - VITE_PYTHON_API_URL=http://localhost:5000
    networks:
      - jobtrack-network
    restart: unless-stopped
    depends_on:
      - backend
      - python-api

networks:
  jobtrack-network:
    driver: bridge

volumes:
  backend-data:
  backend-export:
  model-backups:

